{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"✅ Elasticsearch security features have been automatically configured!\n",
    "✅ Authentication is enabled and cluster connections are encrypted.\n",
    "\n",
    "ℹ️  Password for the elastic user (reset with `bin/elasticsearch-reset-password -u elastic`):\n",
    "  7l5NNDht_jsMzzExtWUo\n",
    "\n",
    "ℹ️  HTTP CA certificate SHA-256 fingerprint:\n",
    "  0fb63522175c33c1842b5b5678986c10fa78b04ae264032beda52c2578683a8e\n",
    "\n",
    "ℹ️  Configure Kibana to use this cluster:\n",
    "• Run Kibana and click the configuration link in the terminal when Kibana starts.\n",
    "• Copy the following enrollment token and paste it into Kibana in your browser (valid for the next 30 minutes):\n",
    "  eyJ2ZXIiOiI4LjEzLjIiLCJhZHIiOlsiMTcyLjE4LjAuMjo5MjAwIl0sImZnciI6IjBmYjYzNTIyMTc1YzMzYzE4NDJiNWI1Njc4OTg2YzEwZmE3OGIwNGFlMjY0MDMyYmVkYTUyYzI1Nzg2ODNhOGUiLCJrZXkiOiJub00xNjQ0Qm8zWXNzYTNvV1ZpQTpXNDAwWUVMeVRwbUtYcEFpeUNfUHZ3In0=\n",
    "\n",
    "ℹ️ Configure other nodes to join this cluster:\n",
    "• Copy the following enrollment token and start new Elasticsearch nodes with `bin/elasticsearch --enrollment-token <token>` (valid for the next 30 minutes):\n",
    "  eyJ2ZXIiOiI4LjEzLjIiLCJhZHIiOlsiMTcyLjE4LjAuMjo5MjAwIl0sImZnciI6IjBmYjYzNTIyMTc1YzMzYzE4NDJiNWI1Njc4OTg2YzEwZmE3OGIwNGFlMjY0MDMyYmVkYTUyYzI1Nzg2ODNhOGUiLCJrZXkiOiJuNE0xNjQ0Qm8zWXNzYTNvV1ZpQTowbHJSX25mYVNSYThkNFBLaGpMLXB3In0=\n",
    "\n",
    "  If you're running in Docker, copy the enrollment token and run:\n",
    "  `docker run -e \"ENROLLMENT_TOKEN=<token>\" docker.elastic.co/elasticsearch/elasticsearch:8.13.2`\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"MHJIdjZJNEJUMHZualkxWFpKV2k6aUVRR0w1R3dSMHFrczFqVnZOcnR4QQ==\"\n",
    "address = \"https://localhost:9200\"\n",
    "password = \"7l5NNDht_jsMzzExtWUo\"\n",
    "fingerprint = \"0fb63522175c33c1842b5b5678986c10fa78b04ae264032beda52c2578683a8e\"\n",
    "enrollment = \"eyJ2ZXIiOiI4LjEzLjIiLCJhZHIiOlsiMTcyLjE4LjAuMzo5MjAwIl0sImZnciI6IjdhYzJmN2U2MGRmOWE0ZTMwMGQwMDAyODc1MWNiMjhjZWVmOTQyMmE2ZGM3OWQ4MWRmZjMwNWEyY2FkNTcyNjEiLCJrZXkiOiJsWjhjNjQ0QklqQkg5UVVZREQ4NDpURndmNng0OVFHU1dCeHpMd1FXNGVRIn0=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '2621eaa976cd', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'DaLmFfnHQNKan2DPS_62NQ', 'version': {'number': '8.13.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '16cc90cd2d08a3147ce02b07e50894bc060a4cbf', 'build_date': '2024-04-05T14:45:26.420424304Z', 'build_snapshot': False, 'lucene_version': '9.10.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Elasticsearch(address, ssl_assert_fingerprint=fingerprint, basic_auth=(\"elastic\", password))\n",
    "client.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\n",
    "    'author': 'author_name',\n",
    "    'text': 'Interesting content...',\n",
    "    'timestamp': datetime.now(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created\n"
     ]
    }
   ],
   "source": [
    "resp = client.index(index=\"test-index\", id=1, document=test)\n",
    "print(resp['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'author_name', 'text': 'Interesting content...', 'timestamp': '2024-04-17T11:55:15.550382'}\n"
     ]
    }
   ],
   "source": [
    "resp =  client.get(index=\"test-index\", id=1)\n",
    "print(resp['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_shards': {'total': 2, 'successful': 1, 'failed': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.refresh(index=\"test-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1 hits. Hits:\n",
      "2024-04-17T11:55:15.550382 author_name: Interesting content...\n"
     ]
    }
   ],
   "source": [
    "resp = client.search(index=\"test-index\", query={\"match_all\": {}})\n",
    "print(f\"Got {resp['hits']['total']['value']} hits. Hits:\")\n",
    "for hit in resp['hits']['hits']:\n",
    "    print(\"%(timestamp)s %(author)s: %(text)s\" % hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated\n"
     ]
    }
   ],
   "source": [
    "doc = {\n",
    "    'author': 'Bob',\n",
    "    'text': 'The quick brown fox jumps over the lazy dog',\n",
    "    'timestamp': datetime.now(),\n",
    "}\n",
    "\n",
    "resp = client.update(index=\"test-index\", id=1, doc=doc)\n",
    "print(resp['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_index': 'test-index', '_id': '1', '_version': 3, 'result': 'deleted', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 2, '_primary_term': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete(index=\"test-index\", id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.delete(index=\"test-index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BadRequestError(400, 'resource_already_exists_exception', 'index [document_index/UpQJ5PAAROajOEW6Nz-4Fg] already exists')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client.indices.create(index=\"document_index\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 5000\n",
      "Processing document 10000\n",
      "Processing document 15000\n",
      "Processing document 17478\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for root, dirs, files in os.walk(\"./davisWiki\"):\n",
    "    for file in files:\n",
    "        with open(os.path.join(root, file), \"r\") as f:\n",
    "            try:\n",
    "                title = file\n",
    "                text = f.read()\n",
    "                doc = {\n",
    "                    \"title\": title,\n",
    "                    \"text\": text,\n",
    "                    \"timestamp\": datetime.now()\n",
    "                }\n",
    "                count += 1\n",
    "                client.index(index=\"document_index\", id=count, document=doc)\n",
    "                if count % 5000 == 0:\n",
    "                    print(f\"Processing document {count}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"title: \", title)\n",
    "                break\n",
    "\n",
    "print(f\"Processing document {count}\") \n",
    "print(\"done\")\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 248 hits. Hits:\n",
      "Kearney_Hall.f\n",
      "Zombie_Walk.f\n",
      "Measure_Z.f\n",
      "Spirit_Halloween.f\n",
      "Zombie_Attack_Response_Guide.f\n",
      "Scream.f\n",
      "Disasters.f\n",
      "Biological_Disasters.f\n",
      "JasonRifkind.f\n",
      "Zombies_Reclaim_the_Streets.f\n"
     ]
    }
   ],
   "source": [
    "query = \"zombie attack\"\n",
    "\n",
    "resp = client.search(index=\"document_index\", body={\"query\": {\n",
    "    \"match\": {\n",
    "        \"text\": query\n",
    "}}, \"size\": 10, \"explain\": True})\n",
    "\n",
    "count = 0 \n",
    "print(f\"Got {resp['hits']['total']['value']} hits. Hits:\")\n",
    "for hit in resp['hits']['hits']:\n",
    "    print(\"%(title)s\" % hit[\"_source\"])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
